run_name: shape_model
dtype: float32

# Model
model_type: 'shape'
energy_model: '/home/aore/calo_dreamer/results/20231105_035151_energy_model'

# Data
hdf5_file: /data/projects/punim0011/aore/CaloChallenge/1/dataset_1_photons_1.hdf5
eval_hdf5_file: /data/projects/punim0011/aore/CaloChallenge/1/dataset_1_photons_2.hdf5
xml_filename: /home/aore/calo_dreamer/src/challenge_files/binning_dataset_1_photons.xml
val_frac: 0.2
eps: 1.0e-10
particle_type: "photon"
eval_dataset: "1-photons"
transforms: {
    NormalizeByElayer: {
        ptype: /home/aore/calo_dreamer/src/challenge_files/binning_dataset_1_photons.xml,
        xml_file: photon
    },
    SelectiveUniformNoise: {noise_width: 5.0e-6, cut: True, exclusions: [-5, -4, -3, -2, -1]},
    SelectiveLogTransform: {
        alpha: 1.0e-6, exclusions: [-5, -4, -3, -2, -1]
    },
    SelectiveLogitTransform: {
        delta: 1.0e-6, inclusions: [-4, -3, -2, -1]
    },
    StandardizeFromFile: {
        mean_path: /home/aore/calo_dreamer/dat/means_1_photons_1.npy,
        std_path: /home/aore/calo_dreamer/dat/stds_1_photons_1.npy,
        create: True
    },
    LogEnergy: {},
    ScaleEnergy: {e_min: 5.545177, e_max: 15.249238},
    AddFeaturesToCond: {split_index: 368}
}

# Training
lr: 5.e-4
max_lr: 5.e-4
batch_size: 2000
validate_every: 1
use_scheduler: True
lr_scheduler: one_cycle_lr
weight_decay: 0.001
betas: [0.9, 0.999]
n_epochs: 10_000
cycle_epochs: 10_000
cycle_pct_start: 0.1
save_interval: 100_001

# Sampling
sample_periodically: False
sample_every: 4001
sample_every_n_samples: 1000

network: Resnet
shape: [368]

# ResNet block
intermediate_dim: 2048
n_blocks: 4
n_con: 6 # Einc + u_i
layers_per_block: 2
conditional: True
encode_t: True
encode_t_dim: 100
encode_c: True
encode_c_dim: 100
normalization: LayerNorm